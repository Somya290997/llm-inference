# config/model_config.yaml

model_name: mistral-7b
model_path: ./mistral_7b_4bit_local 
quantization: 4bit  
compute_dtype: float16
vocab_tokens: 32000
use_flash_attention: true

batch_size: 1
max_input_tokens: 512
max_output_tokens: 128
num_layers: 32
hidden_size: 4096
n_dim: 128
n_heads: 8
kv_cache_dtype: float16

prefill_gpu: 1
decode_gpu: 0